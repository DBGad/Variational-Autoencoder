# ğŸ§  Variational Autoencoder (VAE) for Image Generation

## ğŸ“Œ Project Overview
This project implements a **Variational Autoencoder (VAE)** for image reconstruction and generation using **TensorFlow / Keras**.

Unlike a standard Autoencoder, the VAE learns a **probabilistic latent representation**, enabling smooth interpolation and generation of new images.

You can also seeing my Recorded Video (Arabic) : [HERE](https://drive.google.com/drive/folders/14l589VBs5csFKALZyA1wHVfQ-rHToE4_?usp=sharing)

---

## ğŸ—‚ï¸ Dataset

- Dataset size: **100,000 images**
- Images are normalized to the range **[0, 1]**
- Data is split into **training** and **validation** sets

### ğŸ“· Sample of Input Data
<img width="982" height="985" alt="Image" src="https://github.com/user-attachments/assets/b2e66179-7835-441a-918e-c16428bc0cf7" />


---

## ğŸ—ï¸ Model Architecture

### ğŸ”¹ Encoder
The encoder maps an input image into a **latent Gaussian distribution**.
```
Input Image
   â†“
Conv2D + ReLU
   â†“
Conv2D + ReLU
   â†“
Conv2D + ReLU
   â†“
Conv2D + ReLU
   â†“
Flatten
   â†“
Dense
   â†“
z_mean , z_log_var
```

**Outputs:**
- `z_mean`: Mean of the latent distribution
- `z_log_var`: Log variance of the latent distribution

Each latent dimension is modeled as:

$$
z \sim \mathcal{N}(\mu, \sigma^2)
$$

---

### ğŸ”¹ Reparameterization Trick
Direct sampling is non-differentiable. To enable backpropagation, the following formulation is used:

$$
z = \mu + \sigma \cdot \epsilon \quad , \quad \epsilon \sim \mathcal{N}(0,1)
$$

This allows gradients to flow through the stochastic sampling process.

---

### ğŸ”¹ Decoder
The decoder reconstructs the image from the latent vector `z` using transposed convolution layers.

```
Latent Vector z
   â†“
Dense
   â†“
Reshape
   â†“
Conv2DTranspose
   â†“
Conv2DTranspose
   â†“
Conv2DTranspose
   â†“
Conv2DTranspose
   â†“
Reconstructed Image
 
```

---

## ğŸ“‰ Loss Function

The VAE is trained using a **combined loss function**:

### 1ï¸âƒ£ Reconstruction Loss
Binary Cross-Entropy between the input image and its reconstruction:

$$
\mathcal{L}_{rec} = \text{BCE}(x, \hat{x})
$$

---

### 2ï¸âƒ£ KL Divergence Loss
Encourages the learned latent distribution to be close to a standard normal distribution:

$$
\mathcal{L}_{KL} = -\frac{1}{2} \sum \left(1 + \log\sigma^2 - \mu^2 - \sigma^2 \right)
$$

This regularization ensures a smooth and continuous latent space.

---

### â• Total Loss

$$
\mathcal{L}_{total} = \mathcal{L}_{rec} + \mathcal{L}_{KL}
$$

---

## ğŸ“Š Training Behavior

- Reconstruction loss decreases steadily
- KL divergence stabilizes at reasonable values
- Validation loss closely follows training loss

This indicates stable and effective training.

---

## ğŸ–¼ï¸ Reconstruction Results

Comparison between original images and reconstructed images:

### ğŸ“· Original vs Reconstructed Images
<img width="1569" height="363" alt="Image" src="https://github.com/user-attachments/assets/94f67762-66f9-4121-a658-f62cb7c390c1" />


---

## ğŸ¨ Image Generation

New images are generated by sampling latent vectors from:

$$
z \sim \mathcal{N}(0,1)
$$

and passing them through the decoder.

### ğŸ“· Generated Images
<img width="781" height="789" alt="Image" src="https://github.com/user-attachments/assets/2e97c7c7-3b48-4dc8-ac1a-25a329638c40" />


---

## ğŸ§¬ Latent Space Interpretation

- Each latent dimension learns its own mean and variance
- KL divergence forces latent distributions to remain close to a standard normal distribution
- Lower KL divergence indicates better regularization of the latent space

---

## âœ… Conclusion

- The VAE successfully learns a probabilistic latent representation
- Reconstruction quality improves throughout training
- The learned latent space is smooth and suitable for image generation
- Backpropagation through sampling is enabled using the reparameterization trick

---

## ğŸš€ Technologies Used

- Python
- TensorFlow / Keras
- NumPy
- Matplotlib

